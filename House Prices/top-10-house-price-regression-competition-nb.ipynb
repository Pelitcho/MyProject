{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycaret\n",
      "  Downloading pycaret-2.3.10-py3-none-any.whl (320 kB)\n",
      "     -------------------------------------- 320.2/320.2 kB 5.0 MB/s eta 0:00:00\n",
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.4.0-py3-none-any.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 20.7 MB/s eta 0:00:00\n",
      "Collecting yellowbrick>=1.0.1\n",
      "  Downloading yellowbrick-1.5-py3-none-any.whl (282 kB)\n",
      "     ------------------------------------- 282.6/282.6 kB 18.2 MB/s eta 0:00:00\n",
      "Collecting pyod\n",
      "  Downloading pyod-1.0.7.tar.gz (147 kB)\n",
      "     ---------------------------------------- 147.7/147.7 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: plotly>=4.4.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pycaret) (5.9.0)\n",
      "Collecting pandas-profiling>=2.8.0\n",
      "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
      "     ---------------------------------------- 324.4/324.4 kB ? eta 0:00:00\n",
      "Collecting scipy<=1.5.4\n",
      "  Downloading scipy-1.5.4-cp38-cp38-win_amd64.whl (31.4 MB)\n",
      "     --------------------------------------- 31.4/31.4 MB 21.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: IPython in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pycaret) (8.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pycaret) (0.12.2)\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-2.1.1-py3-none-any.whl (16.7 MB)\n",
      "     --------------------------------------- 16.7/16.7 MB 27.3 MB/s eta 0:00:00\n",
      "Collecting umap-learn\n",
      "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
      "     ---------------------------------------- 88.2/88.2 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pycaret) (1.5.2)\n",
      "Collecting mlxtend>=0.17.0\n",
      "  Downloading mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 43.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pycaret) (7.6.5)\n",
      "Requirement already satisfied: nltk in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pycaret) (3.7)\n",
      "Collecting gensim<4.0.0\n",
      "  Downloading gensim-3.8.3-cp38-cp38-win_amd64.whl (24.2 MB)\n",
      "     --------------------------------------- 24.2/24.2 MB 11.5 MB/s eta 0:00:00\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.2.2-cp38-cp38-win_amd64.whl (152 kB)\n",
      "     -------------------------------------- 152.9/152.9 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     ------------------------------------- 636.8/636.8 kB 39.2 MB/s eta 0:00:00\n",
      "Collecting lightgbm>=2.3.1\n",
      "  Downloading lightgbm-3.3.5-py3-none-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 32.7 MB/s eta 0:00:00\n",
      "Collecting kmodes>=0.10.1\n",
      "  Downloading kmodes-0.12.2-py2.py3-none-any.whl (20 kB)\n",
      "Collecting numba<0.55\n",
      "  Downloading numba-0.54.1-cp38-cp38-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 11.2 MB/s eta 0:00:00\n",
      "Collecting Boruta\n",
      "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 56.6/56.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pycaret) (3.6.2)\n",
      "Collecting scikit-plot\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pycaret) (1.1.1)\n",
      "Collecting scikit-learn==0.23.2\n",
      "  Downloading scikit_learn-0.23.2-cp38-cp38-win_amd64.whl (6.8 MB)\n",
      "     ---------------------------------------- 6.8/6.8 MB 21.8 MB/s eta 0:00:00\n",
      "Collecting cufflinks>=0.17.0\n",
      "  Downloading cufflinks-0.17.3.tar.gz (81 kB)\n",
      "     ---------------------------------------- 81.7/81.7 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting imbalanced-learn==0.7.0\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "     -------------------------------------- 167.1/167.1 kB 9.8 MB/s eta 0:00:00\n",
      "Collecting spacy<2.4.0\n",
      "  Downloading spacy-2.3.9-cp38-cp38-win_amd64.whl (9.4 MB)\n",
      "     ---------------------------------------- 9.4/9.4 MB 9.1 MB/s eta 0:00:00\n",
      "Collecting pyyaml<6.0.0\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-win_amd64.whl (213 kB)\n",
      "     ------------------------------------- 213.6/213.6 kB 12.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from imbalanced-learn==0.7.0->pycaret) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from scikit-learn==0.23.2->pycaret) (2.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from cufflinks>=0.17.0->pycaret) (1.16.0)\n",
      "Collecting colorlover>=0.2.1\n",
      "  Downloading colorlover-0.3.0-py3-none-any.whl (8.9 kB)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from cufflinks>=0.17.0->pycaret) (65.6.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from gensim<4.0.0->pycaret) (5.2.1)\n",
      "Collecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 21.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (2.11.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (3.0.36)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (5.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.4.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.1.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.18.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipywidgets->pycaret) (1.0.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipywidgets->pycaret) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipywidgets->pycaret) (3.5.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipywidgets->pycaret) (6.19.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipywidgets->pycaret) (5.7.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from lightgbm>=2.3.1->pycaret) (0.38.4)\n",
      "Collecting mlxtend>=0.17.0\n",
      "  Downloading mlxtend-0.20.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 21.2 MB/s eta 0:00:00\n",
      "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 28.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (9.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (1.4.4)\n",
      "Collecting llvmlite<0.38,>=0.37.0rc1\n",
      "  Downloading llvmlite-0.37.0-cp38-cp38-win_amd64.whl (17.0 MB)\n",
      "     ---------------------------------------- 17.0/17.0 MB 5.6 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.13.3\n",
      "  Downloading numpy-1.20.3-cp38-cp38-win_amd64.whl (13.7 MB)\n",
      "     --------------------------------------- 13.7/13.7 MB 28.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pandas->pycaret) (2022.7)\n",
      "Collecting ydata-profiling\n",
      "  Downloading ydata_profiling-4.0.0-py2.py3-none-any.whl (344 kB)\n",
      "     ---------------------------------------- 344.5/344.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from plotly>=4.4.1->pycaret) (8.0.1)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.6-cp38-cp38-win_amd64.whl (198 kB)\n",
      "     ---------------------------------------- 198.8/198.8 kB ? eta 0:00:00\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp38-cp38-win_amd64.whl (18 kB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp38-cp38-win_amd64.whl (30 kB)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.9-cp38-cp38-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 22.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from spacy<2.4.0->pycaret) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from spacy<2.4.0->pycaret) (2.28.1)\n",
      "Collecting thinc<7.5.0,>=7.4.1\n",
      "  Downloading thinc-7.4.6-cp38-cp38-win_amd64.whl (831 kB)\n",
      "     ------------------------------------- 831.4/831.4 kB 10.4 MB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp38-cp38-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 96.7/96.7 kB ? eta 0:00:00\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting yellowbrick>=1.0.1\n",
      "  Downloading yellowbrick-1.4-py3-none-any.whl (274 kB)\n",
      "     ------------------------------------- 274.2/274.2 kB 16.5 MB/s eta 0:00:00\n",
      "  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
      "     ------------------------------------- 271.4/271.4 kB 17.4 MB/s eta 0:00:00\n",
      "  Downloading yellowbrick-1.3-py3-none-any.whl (271 kB)\n",
      "     ------------------------------------- 271.3/271.3 kB 16.3 MB/s eta 0:00:00\n",
      "  Downloading yellowbrick-1.2.1-py3-none-any.whl (269 kB)\n",
      "     ------------------------------------- 269.5/269.5 kB 17.3 MB/s eta 0:00:00\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Downloading databricks-cli-0.17.4.tar.gz (82 kB)\n",
      "     ---------------------------------------- 82.3/82.3 kB 4.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Flask<3 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from mlflow->pycaret) (2.2.2)\n",
      "Collecting shap<1,>=0.40\n",
      "  Downloading shap-0.41.0-cp38-cp38-win_amd64.whl (435 kB)\n",
      "     ------------------------------------- 435.6/435.6 kB 26.6 MB/s eta 0:00:00\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.8/42.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from mlflow->pycaret) (3.1.2)\n",
      "Collecting protobuf<5,>=3.12.0\n",
      "  Downloading protobuf-4.22.0-cp38-cp38-win_amd64.whl (420 kB)\n",
      "     ------------------------------------- 420.6/420.6 kB 25.6 MB/s eta 0:00:00\n",
      "Collecting alembic<2\n",
      "  Downloading alembic-1.9.4-py3-none-any.whl (210 kB)\n",
      "     ---------------------------------------- 210.5/210.5 kB ? eta 0:00:00\n",
      "Collecting pyarrow<11,>=4.0.0\n",
      "  Downloading pyarrow-10.0.1-cp38-cp38-win_amd64.whl (20.3 MB)\n",
      "     --------------------------------------- 20.3/20.3 MB 24.3 MB/s eta 0:00:00\n",
      "Collecting waitress<3\n",
      "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.7/57.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: entrypoints<1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from mlflow->pycaret) (0.4)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from mlflow->pycaret) (3.4.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from mlflow->pycaret) (8.0.4)\n",
      "Collecting docker<7,>=4.0.0\n",
      "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
      "     -------------------------------------- 147.5/147.5 kB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<6,>=3.7.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from mlflow->pycaret) (4.11.3)\n",
      "Requirement already satisfied: cloudpickle<3 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from mlflow->pycaret) (2.0.0)\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "     ---------------------------------------- 184.3/184.3 kB ? eta 0:00:00\n",
      "Collecting querystring-parser<2\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from mlflow->pycaret) (1.4.39)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nltk->pycaret) (2022.7.9)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.18-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: numexpr in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pyLDAvis->pycaret) (2.8.4)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ---------------------------------------- 298.0/298.0 kB ? eta 0:00:00\n",
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 26.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: future in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pyLDAvis->pycaret) (0.18.2)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: statsmodels in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pyod->pycaret) (0.13.5)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 24.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from alembic<2->mlflow->pycaret) (5.2.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.7/78.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow->pycaret) (2.4.0)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow->pycaret) (0.8.10)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from docker<7,>=4.0.0->mlflow->pycaret) (1.26.14)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from docker<7,>=4.0.0->mlflow->pycaret) (305.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from docker<7,>=4.0.0->mlflow->pycaret) (0.58.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from Flask<3->mlflow->pycaret) (2.2.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from Flask<3->mlflow->pycaret) (2.0.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow->pycaret) (3.11.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.9.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.1.12)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (23.2.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (1.5.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (1.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from jedi>=0.16->IPython->pycaret) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow->pycaret) (2.1.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (5.2.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.17.3)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.30->IPython->pycaret) (0.2.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->pycaret) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->pycaret) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->pycaret) (2.0.4)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from sqlalchemy<2,>=1.4.0->mlflow->pycaret) (2.0.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (6.5.2)\n",
      "Requirement already satisfied: executing in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from stack-data->IPython->pycaret) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from stack-data->IPython->pycaret) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from stack-data->IPython->pycaret) (0.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from statsmodels->pyod->pycaret) (0.5.3)\n",
      "Collecting pydantic<1.11,>=1.8.1\n",
      "  Downloading pydantic-1.10.5-cp38-cp38-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 23.3 MB/s eta 0:00:00\n",
      "Collecting phik<0.13,>=0.11.1\n",
      "  Downloading phik-0.12.3-cp38-cp38-win_amd64.whl (663 kB)\n",
      "     ------------------------------------- 663.3/663.3 kB 43.5 MB/s eta 0:00:00\n",
      "Collecting visions[type_image_path]==0.7.5\n",
      "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "     ---------------------------------------- 102.7/102.7 kB ? eta 0:00:00\n",
      "Collecting htmlmin==0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting multimethod<1.10,>=1.4\n",
      "  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
      "Collecting typeguard<2.14,>=2.13.2\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (22.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (2.8.4)\n",
      "Collecting tangled-up-in-unicode>=0.0.4\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 27.4 MB/s eta 0:00:00\n",
      "Collecting imagehash\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "     ---------------------------------------- 296.5/296.5 kB ? eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pycaret) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pycaret) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets->pycaret) (2.5.2)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.14.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.17.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.2)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (21.3.0)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (6.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from pydantic<1.11,>=1.8.1->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (4.4.0)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.23.4)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.2.2)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.2.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (4.9.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (4.1.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (4.11.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.13)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (2.0.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (21.2.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (1.4.1)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hippolyte\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (2.21)\n",
      "Building wheels for collected packages: cufflinks, pyLDAvis, pyod, umap-learn, databricks-cli, pynndescent, sklearn, htmlmin\n",
      "  Building wheel for cufflinks (setup.py): started\n",
      "  Building wheel for cufflinks (setup.py): finished with status 'done'\n",
      "  Created wheel for cufflinks: filename=cufflinks-0.17.3-py3-none-any.whl size=68725 sha256=0bd67d0db26bf16e0950b692785cb7f837c78763d7a890961512c1fd34e2c9d7\n",
      "  Stored in directory: c:\\users\\hippolyte\\appdata\\local\\pip\\cache\\wheels\\8b\\0c\\8c\\6b052b6e9281a66c0618959319eb404b1ae6dba84c5505a4c6\n",
      "  Building wheel for pyLDAvis (pyproject.toml): started\n",
      "  Building wheel for pyLDAvis (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136904 sha256=5a43876f51321e195b643be2ee85b201b9fbf8bf975d954295183a99cd9f7e27\n",
      "  Stored in directory: c:\\users\\hippolyte\\appdata\\local\\pip\\cache\\wheels\\62\\73\\dd\\e1723cb4dfe5b31bf4719e640a6f9a28f488225e0af46a3514\n",
      "  Building wheel for pyod (setup.py): started\n",
      "  Building wheel for pyod (setup.py): finished with status 'done'\n",
      "  Created wheel for pyod: filename=pyod-1.0.7-py3-none-any.whl size=181151 sha256=0a7a659fce52fffb9db3be16557b6fbcb5647f91ead0a01bc42dd0b30d6699c6\n",
      "  Stored in directory: c:\\users\\hippolyte\\appdata\\local\\pip\\cache\\wheels\\d1\\3b\\3a\\23d2c32d0fb16e7d5afb28e379c310a2c6789e853976a941a3\n",
      "  Building wheel for umap-learn (setup.py): started\n",
      "  Building wheel for umap-learn (setup.py): finished with status 'done'\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82909 sha256=9bc7b97a352eda9b0c6afe0e667aa7cea5f45a93f9eae3f33ba12f0a3305d72d\n",
      "  Stored in directory: c:\\users\\hippolyte\\appdata\\local\\pip\\cache\\wheels\\de\\b2\\e6\\f3710dd75722ad40e856825ebdb090021a774e59f07d39bfc6\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142900 sha256=f60e6a6e679e5036079c8a2db7cffc7472109f24012b66f392893df5ec0996cd\n",
      "  Stored in directory: c:\\users\\hippolyte\\appdata\\local\\pip\\cache\\wheels\\0a\\0b\\75\\44edb38430dc44de74324d6e72d91d0d14d21df90349767335\n",
      "  Building wheel for pynndescent (setup.py): started\n",
      "  Building wheel for pynndescent (setup.py): finished with status 'done'\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55547 sha256=dca63c851c32b97014bab89b6d2cb94233b59b884b83ab954fe17950105d298d\n",
      "  Stored in directory: c:\\users\\hippolyte\\appdata\\local\\pip\\cache\\wheels\\c9\\24\\e3\\9668804f30023bd253f22a9c37befce9d70a1f6507d7010c42\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2954 sha256=c7b537a71f11c8c649e5475e6d64833a79f98df2536ed43914c80269e7143951\n",
      "  Stored in directory: c:\\users\\hippolyte\\appdata\\local\\pip\\cache\\wheels\\1c\\2f\\26\\476423e3abcbdc095c9061b4a385339f4d5c4952c036ef8262\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27092 sha256=7e88cc5862bb5f2a6ab80523c5c2bb3b7478d8287e01b0b435af68fff04d29dd\n",
      "  Stored in directory: c:\\users\\hippolyte\\appdata\\local\\pip\\cache\\wheels\\28\\f3\\26\\826f91b0c848ff98f1725cd43014a6f3a2d961114157d790db\n",
      "Successfully built cufflinks pyLDAvis pyod umap-learn databricks-cli pynndescent sklearn htmlmin\n",
      "Installing collected packages: wasabi, sklearn, plac, htmlmin, funcy, cymem, colorlover, waitress, typeguard, tangled-up-in-unicode, srsly, sqlparse, smmap, slicer, querystring-parser, pyyaml, pydantic, protobuf, oauthlib, numpy, murmurhash, multimethod, Mako, llvmlite, Cython, catalogue, scipy, pyarrow, preshed, numba, gitdb, docker, databricks-cli, blis, alembic, visions, thinc, textblob, scikit-learn, imagehash, gitpython, gensim, yellowbrick, wordcloud, spacy, shap, scikit-plot, pyod, pynndescent, pyLDAvis, phik, mlxtend, lightgbm, kmodes, imbalanced-learn, Boruta, ydata-profiling, umap-learn, mlflow, pandas-profiling, cufflinks, pycaret\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.39.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "!pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "'Pattern matched multiple keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_columns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m90\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_config\\config.py:263\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_config\\config.py:156\u001b[0m, in \u001b[0;36m_set_option\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_set_option() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwarg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args[::\u001b[38;5;241m2\u001b[39m], args[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m--> 156\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     o \u001b[38;5;241m=\u001b[39m _get_registered_option(key)\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m o \u001b[38;5;129;01mand\u001b[39;00m o\u001b[38;5;241m.\u001b[39mvalidator:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_config\\config.py:123\u001b[0m, in \u001b[0;36m_get_single_key\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such keys(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(pat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPattern matched multiple keys\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m key \u001b[38;5;241m=\u001b[39m keys[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n",
      "\u001b[1;31mOptionError\u001b[0m: 'Pattern matched multiple keys'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', 90)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pycaret.regression import setup, compare_models\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import BayesianRidge, HuberRegressor, Ridge, OrthogonalMatchingPursuit\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
    "test0 = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\n",
    "sample_submission = pd.read_csv('../input/house-prices-advanced-regression-techniques/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train0['SalePrice']\n",
    "test_ids = test0['Id']\n",
    "\n",
    "train1 = train0.drop(['Id', 'SalePrice'], axis=1)\n",
    "test1 = test0.drop('Id', axis=1)\n",
    "\n",
    "data1 = pd.concat([train1, test1], axis=0).reset_index(drop=True)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure Proper Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['MSSubClass'] = data2['MSSubClass'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Categorical Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute using a constant value\n",
    "for column in [\n",
    "    'Alley',\n",
    "    'BsmtQual',\n",
    "    'BsmtCond',\n",
    "    'BsmtExposure',\n",
    "    'BsmtFinType1',\n",
    "    'BsmtFinType2',\n",
    "    'FireplaceQu',\n",
    "    'GarageType',\n",
    "    'GarageFinish',\n",
    "    'GarageQual',\n",
    "    'GarageCond',\n",
    "    'PoolQC',\n",
    "    'Fence',\n",
    "    'MiscFeature'\n",
    "]:\n",
    "    data2[column] = data2[column].fillna(\"None\")\n",
    "\n",
    "# Impute using the column mode\n",
    "for column in [\n",
    "    'MSZoning',\n",
    "    'Utilities',\n",
    "    'Exterior1st',\n",
    "    'Exterior2nd',\n",
    "    'MasVnrType',\n",
    "    'Electrical',\n",
    "    'KitchenQual',\n",
    "    'Functional',\n",
    "    'SaleType'\n",
    "]:\n",
    "    data2[column] = data2[column].fillna(data2[column].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute(df, na_target):\n",
    "    df = df.copy()\n",
    "    \n",
    "    numeric_df = df.select_dtypes(np.number)\n",
    "    non_na_columns = numeric_df.loc[: ,numeric_df.isna().sum() == 0].columns\n",
    "    \n",
    "    y_train = numeric_df.loc[numeric_df[na_target].isna() == False, na_target]\n",
    "    X_train = numeric_df.loc[numeric_df[na_target].isna() == False, non_na_columns]\n",
    "    X_test = numeric_df.loc[numeric_df[na_target].isna() == True, non_na_columns]\n",
    "    \n",
    "    knn = KNeighborsRegressor()\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    df.loc[df[na_target].isna() == True, na_target] = y_pred\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\n",
    "    'LotFrontage',\n",
    "    'MasVnrArea',\n",
    "    'BsmtFinSF1',\n",
    "    'BsmtFinSF2',\n",
    "    'BsmtUnfSF',\n",
    "    'TotalBsmtSF',\n",
    "    'BsmtFullBath',\n",
    "    'BsmtHalfBath',\n",
    "    'GarageYrBlt',\n",
    "    'GarageCars',\n",
    "    'GarageArea'\n",
    "]:\n",
    "    data3 = knn_impute(data3, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4[\"SqFtPerRoom\"] = data4[\"GrLivArea\"] / (data4[\"TotRmsAbvGrd\"] +\n",
    "                                                       data4[\"FullBath\"] +\n",
    "                                                       data4[\"HalfBath\"] +\n",
    "                                                       data4[\"KitchenAbvGr\"])\n",
    "\n",
    "data4['Total_Home_Quality'] = data4['OverallQual'] + data4['OverallCond']\n",
    "\n",
    "data4['Total_Bathrooms'] = (data4['FullBath'] + (0.5 * data4['HalfBath']) +\n",
    "                               data4['BsmtFullBath'] + (0.5 * data4['BsmtHalfBath']))\n",
    "\n",
    "data4[\"HighQualSF\"] = data4[\"1stFlrSF\"] + data4[\"2ndFlrSF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Transform for Skewed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_df = pd.DataFrame(data5.select_dtypes(np.number).columns, columns=['Feature'])\n",
    "skew_df['Skew'] = skew_df['Feature'].apply(lambda feature: scipy.stats.skew(data5[feature]))\n",
    "skew_df['Absolute Skew'] = skew_df['Skew'].apply(abs)\n",
    "skew_df['Skewed'] = skew_df['Absolute Skew'].apply(lambda x: True if x >= 0.5 else False)\n",
    "skew_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in skew_df.query(\"Skewed == True\")['Feature'].values:\n",
    "    data5[column] = np.log1p(data5[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Transform for Cyclical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['MoSold'] = (-np.cos(0.5236 * data5['MoSold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 = data5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 = pd.get_dummies(data6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7 = data6.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(data7)\n",
    "\n",
    "data7 = pd.DataFrame(scaler.transform(data7), index=data7.index, columns=data7.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data8 = data7.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.distplot(target, kde=True, fit=scipy.stats.norm)\n",
    "plt.title(\"Without Log Transform\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.distplot(np.log(target), kde=True, fit=scipy.stats.norm)\n",
    "plt.xlabel(\"Log SalePrice\")\n",
    "plt.title(\"With Log Transform\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_target = np.log(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = data8.loc[:train0.index.max(), :].copy()\n",
    "test_final = data8.loc[train0.index.max() + 1:, :].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = setup(data=pd.concat([train_final, log_target], axis=1), target='SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def br_objective(trial):\n",
    "#     n_iter = trial.suggest_int('n_iter', 50, 600)\n",
    "#     tol = trial.suggest_loguniform('tol', 1e-8, 10.0)\n",
    "#     alpha_1 = trial.suggest_loguniform('alpha_1', 1e-8, 10.0)\n",
    "#     alpha_2 = trial.suggest_loguniform('alpha_2', 1e-8, 10.0)\n",
    "#     lambda_1 = trial.suggest_loguniform('lambda_1', 1e-8, 10.0)\n",
    "#     lambda_2 = trial.suggest_loguniform('lambda_2', 1e-8, 10.0)\n",
    "    \n",
    "#     model = BayesianRidge(\n",
    "#         n_iter=n_iter,\n",
    "#         tol=tol,\n",
    "#         alpha_1=alpha_1,\n",
    "#         alpha_2=alpha_2,\n",
    "#         lambda_1=lambda_1,\n",
    "#         lambda_2=lambda_2\n",
    "#     )\n",
    "    \n",
    "#     model.fit(train_final, log_target)\n",
    "    \n",
    "#     cv_scores = np.exp(np.sqrt(-cross_val_score(model, train_final, log_target, scoring='neg_mean_squared_error', cv=kf)))\n",
    "    \n",
    "#     return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(br_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 6000,\n",
    "    'learning_rate': 0.005,\n",
    "    'depth': 4,\n",
    "    'l2_leaf_reg': 1,\n",
    "    'eval_metric':'RMSE',\n",
    "    'early_stopping_rounds': 200,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "br_params = {\n",
    "    'n_iter': 304,\n",
    "    'tol': 0.16864712769300896,\n",
    "    'alpha_1': 5.589616542154059e-07,\n",
    "    'alpha_2': 9.799343618469923,\n",
    "    'lambda_1': 1.7735725582463822,\n",
    "    'lambda_2': 3.616928181181732e-06\n",
    "}\n",
    "\n",
    "lightgbm_params = {\n",
    "    'num_leaves': 39,\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.13705339989856127,\n",
    "    'n_estimators': 273\n",
    "}\n",
    "\n",
    "ridge_params = {\n",
    "    'alpha': 631.1412445239156\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"catboost\": CatBoostRegressor(**catboost_params, verbose=0),\n",
    "    \"br\": BayesianRidge(**br_params),\n",
    "    \"lightgbm\": LGBMRegressor(**lightgbm_params),\n",
    "    \"ridge\": Ridge(**ridge_params),\n",
    "    \"omp\": OrthogonalMatchingPursuit()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(train_final, log_target)\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for name, model in models.items():\n",
    "    result = np.exp(np.sqrt(-cross_val_score(model, train_final, log_target, scoring='neg_mean_squared_error', cv=kf)))\n",
    "    results[name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, result in results.items():\n",
    "    print(\"----------\\n\" + name)\n",
    "    print(np.mean(result))\n",
    "    print(np.std(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = (\n",
    "    0.4 * np.exp(models['catboost'].predict(test_final)) +\n",
    "    0.2 * np.exp(models['br'].predict(test_final)) +\n",
    "    0.2 * np.exp(models['lightgbm'].predict(test_final)) +\n",
    "    0.1 * np.exp(models['ridge'].predict(test_final)) +\n",
    "    0.1 * np.exp(models['omp'].predict(test_final))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test_ids, pd.Series(final_predictions, name='SalePrice')], axis=1)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livestream Included!\n",
    "\n",
    "***\n",
    "\n",
    "This notebook was created during a YouTube live session.  \n",
    "For an in-depth guide, check it out here!  \n",
    "https://youtu.be/zwYHloLXH0c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
